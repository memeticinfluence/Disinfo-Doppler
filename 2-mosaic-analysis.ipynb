{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic Analysis\n",
    "In this notebook we will used convolutional features and image metadata to generate visual mosaics over time.\n",
    "\n",
    "To do so, we must transform our dimension-rich data into 2-dimensions. There are a trove of techniques to do dimensionality reduction, but in this case we'll be using an algorithm called UMap. UMap is unique because it allows us to persist the model and reuse it. This allows us to project our data into the same 2-dimensional latent space with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ly501/anaconda3/lib/python3.6/site-packages/numba/errors.py:102: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil import relativedelta\n",
    "import json\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "import matplotlib.pyplot\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from tqdm import tqdm\n",
    "import umap.umap_ as umap\n",
    "from rasterfairy import transformPointCloud2D\n",
    "\n",
    "from config import cols_conv_feats, image_lookup_file, skip_hash, logits_file, working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv = pd.read_csv(logits_file, index_col=0, \n",
    "                      nrows=100000, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Params\n",
    "n_neighbors = 25\n",
    "metric = 'minkowski'\n",
    "min_dist = 0.25\n",
    "\n",
    "sample_size = 8000\n",
    "\n",
    "# Model files\n",
    "encoder_file = (f'{working_dir}/encoder_{str(min_dist).replace(\".\", \"-\")}_'\n",
    "                f'dist_{ metric }_sample_{ sample_size }.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = df_conv[cols_conv_feats].sample(sample_size, random_state=303)\n",
    "sample_dataset.to_csv(f'{working_dir}/umap_training_data.csv')\n",
    "\n",
    "encoder = umap.UMAP(n_neighbors=n_neighbors,\n",
    "                    min_dist=min_dist,\n",
    "                    metric=metric,\n",
    "                    random_state=303,\n",
    "                    verbose=1).fit(sample_dataset.values)\n",
    "\n",
    "joblib.dump(encoder, encoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dill.dump(encoder, open(encoder_file.replace('.pkl', '__dill.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a scatterplot, we use Mario Klingmann's RasterFairy software to convert this pointcloud into neat rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = joblib.load(encoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = dill.load(open(encoder_file.replace('.pkl', '__dill.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = pd.read_json(image_lookup_file, lines=True, \n",
    "                        orient='records', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = df_media[~df_media['d_hash'].isin(skip_hash)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_conv.merge(df_media.set_index('d_hash'), \n",
    "                          how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "tile_width = 72\n",
    "tile_height = 56\n",
    "nx = 50\n",
    "ny = 40\n",
    "sample_size = nx * ny\n",
    "\n",
    "# whaddup\n",
    "df_sample = df_merged[i * sample_size : (i + 1) * sample_size]\n",
    "images = df_sample.f_img\n",
    "embeddings = encoder.transform(df_sample[cols_conv_feats].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4000\n",
    "height = 3000\n",
    "max_dim = 100\n",
    "\n",
    "tx, ty = embeddings[:,0], embeddings[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))\n",
    "\n",
    "full_image = Image.new('RGB', \n",
    "                       size=(width, height), \n",
    "                       color=(55, 61, 71))\n",
    "\n",
    "for img, x, y in tqdm(zip(images, tx, ty)):\n",
    "    tile = Image.open(img)\n",
    "    # resize image\n",
    "    rs = max(1, tile.width / max_dim, tile.height / max_dim)\n",
    "    tile_width = int(tile.width / rs)\n",
    "    tile_height = int(tile.height / rs)\n",
    "    tile_dims = (tile_width, tile_height)\n",
    "    tile = tile.resize(size=tile_dims, \n",
    "                       resample=Image.ANTIALIAS)\n",
    "    # add the image to the graph               \n",
    "    x_coord = int((width - max_dim) * x)\n",
    "    y_coord = int((height - max_dim) * y)\n",
    "    img_coords = (x_coord, y_coord)\n",
    "    full_image.paste(tile, box=img_coords,\n",
    "                     mask=tile.convert('RGBA'))\n",
    "\n",
    "matplotlib.pyplot.figure(figsize = (16,12))\n",
    "imshow(full_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign to grid\n",
    "grid_assignment = transformPointCloud2D(embeddings, \n",
    "                                        target=(nx, ny))\n",
    "\n",
    "full_width = tile_width * nx\n",
    "full_height = tile_height * (ny +1)\n",
    "aspect_ratio = float(tile_width) / tile_height\n",
    "\n",
    "grid_image = Image.new('RGB', (full_width, full_height))\n",
    "\n",
    "for img, grid_pos in tqdm(zip(images, grid_assignment[0])):\n",
    "    idx_x, idx_y = grid_pos\n",
    "    x, y = tile_width * idx_x, tile_height * idx_y\n",
    "    try:\n",
    "        tile = Image.open(img)\n",
    "        tile_ar = float(tile.width) / tile.height  # center-crop the tile to match aspect_ratio\n",
    "        if (tile_ar > aspect_ratio):\n",
    "            margin = 0.5 * (tile.width - aspect_ratio * tile.height)\n",
    "            tile = tile.crop((margin, 0, margin + aspect_ratio * tile.height, tile.height))\n",
    "        else:\n",
    "            margin = 0.5 * (tile.height - float(tile.width) / aspect_ratio)\n",
    "            tile = tile.crop((0, margin, tile.width, margin + float(tile.width) / aspect_ratio))\n",
    "        tile = tile.resize((tile_width, tile_height), Image.ANTIALIAS)\n",
    "        grid_image.paste(tile, (int(x), int(y)))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# write an annotation\n",
    "fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', tile_height - 6)\n",
    "draw = ImageDraw.Draw(grid_image)\n",
    "draw.text((4, tile_height * (ny)), \n",
    "          f\"Mosaic of r/dankmemes via PushShift.io @LeonYin\", \n",
    "          (128, 255, 0), font=fnt)\n",
    "\n",
    "grid_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animations\n",
    "We can create animations with these GIFs by sorting our initial dataset by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import imageio\n",
    "\n",
    "# pattern = '/beegfs/ly501/tiles/pol/charlottesville_100/pol_2000_[0-9][0-9][0-9][0-9][0-9][0-9].jpg'\n",
    "# out = '/beegfs/ly501/tiles/pol/gif/charlotte_100_out_30fps_august.gif'\n",
    "\n",
    "# def make_gif(pattern, dest, duration= .25):\n",
    "#     '''\n",
    "#     Saves a png for each congress into the figs subdirectory.\n",
    "#     Uses ImageIO to combine images into a gif.\n",
    "#     Deletes all png files in directory.\n",
    "#     '''\n",
    "\n",
    "#     filenames = glob.glob(pattern)\n",
    "#     filenames.sort()\n",
    "#     images = []\n",
    "\n",
    "#     for filename in filenames:\n",
    "#         images.append(imageio.imread(filename))\n",
    "\n",
    "#     kwargs = { 'duration': duration }\n",
    "#     imageio.mimsave(dest, images,  **kwargs)\n",
    "\n",
    "# def make_mp4(pattern, dest, duration=30):\n",
    "#     '''\n",
    "#     Saves a png for each congress into the figs subdirectory.\n",
    "#     Uses ImageIO to combine images into a gif.\n",
    "#     Deletes all png files in directory.\n",
    "#     '''\n",
    "#     filenames = glob.glob(pattern)\n",
    "#     filenames.sort()\n",
    "#     images = []\n",
    "\n",
    "#     writer = imageio.get_writer(dest, fps=duration)\n",
    "#     for filename in filenames:\n",
    "#         writer.append_data(imageio.imread(filename))\n",
    "#     writer.close()\n",
    "\n",
    "# make_mp4(pattern, out, duration = 23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
