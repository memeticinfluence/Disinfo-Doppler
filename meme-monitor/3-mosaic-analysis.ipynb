{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic Analysis\n",
    "See this on [Github](https://github.com/yinleon/doppler_tutorials/blob/master/2-mosaic-analysis.ipynb), [NbViewer](https://nbviewer.jupyter.org/github/yinleon/doppler_tutorials/blob/master/2-mosaic-analysis.ipynb)<br>\n",
    "By Jansen Derr 2021-02-22<br>\n",
    "\n",
    "In this notebook we will used convolutional features and image metadata to generate visual mosaics over time.\n",
    "\n",
    "To do so, we must transform our dimension-rich data into 2-dimensions. There are a trove of techniques to do dimensionality reduction, but in this case we'll be using an algorithm called UMap. UMap is unique because it allows us to persist the model and reuse it. This allows us to project our data into the same 2-dimensional latent space with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "from matplotlib.pyplot import imshow\n",
    "import imageio\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import joblib\n",
    "import umap\n",
    "import numba\n",
    "from IPython.display import IFrame\n",
    "from rasterfairy import transformPointCloud2D\n",
    "from datetime import datetime\n",
    "\n",
    "import config\n",
    "from image_utils import resize_image, read_image\n",
    "import mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba.__version__, umap.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Fitting UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Params\n",
    "n_neighbors = 25\n",
    "metric = 'euclidean'\n",
    "min_dist = 0.5\n",
    "training_set_size = config.umap_training_set_size\n",
    "overwrite_model = False # set to True to re-train the model.\n",
    "\n",
    "# Model files\n",
    "file_encoder = (f'{ config.working_dir }/encoder_{ str(min_dist).replace(\".\", \"-\") }_'\n",
    "                f'dist_{ metric }_sample_{ training_set_size }.pkl')\n",
    "file_training_set = f'{ config.working_dir }/umap_training_data_{ training_set_size }.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(file_encoder) or overwrite_model:\n",
    "    # Create the training set (note: UMAP can be either supervised or unsupervised.)\n",
    "    if not os.path.exists(file_training_set):\n",
    "        df_conv = pd.read_csv(config.logits_file, \n",
    "                              index_col=0, \n",
    "                              compression='gzip')\n",
    "        training_set = df_conv[config.cols_conv_feats].sample(training_set_size, \n",
    "                                                              random_state=303)\n",
    "    else:\n",
    "        training_set = pd.read_csv(file_training_set, \n",
    "                                   index_col=0)\n",
    "    \n",
    "    # fit the model scikit-learn style\n",
    "    encoder = umap.UMAP(n_neighbors=n_neighbors,\n",
    "                        min_dist=min_dist,\n",
    "                        metric=metric,\n",
    "                        random_state=303,\n",
    "                        verbose=1).fit(training_set.values)\n",
    "\n",
    "    # save the model for later! Save the training data, too.\n",
    "    joblib.dump(encoder, file_encoder)                             \n",
    "    training_set.to_csv(file_training_set)\n",
    "else:\n",
    "    encoder = joblib.load(file_encoder)\n",
    "    encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a scatterplot, we use Mario Klingmann's RasterFairy software to convert this pointcloud into neat rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and Visualization\n",
    "Here we will reduce the convolutional features from 2048-dimensions to 2-dimensions so they are easy to visualize. We'll need to join in each image's metadata (including the path of each file) to the convolutonal features creating `df_merge`. We'll take a sample of that data and visualize it as a scatterplot of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the image metadata with convolutional features\n",
    "if not os.path.exists(config.full_metadata_file):\n",
    "    # Read image metadata\n",
    "    df_media = pd.read_csv(config.image_lookup_file, \n",
    "                           compression='gzip')\n",
    "    df_media = df_media[~df_media['d_hash'].isin(config.skip_hash)]\n",
    "    print(len(df_media))\n",
    "    \n",
    "    df_conv = pd.read_csv(config.logits_file, \n",
    "                          index_col=0, \n",
    "                          compression='gzip')\n",
    "    print(len(df_conv))\n",
    "    # Merge the datasets\n",
    "    merge_cols = [c for c in df_media.columns if c != 'f_img']\n",
    "    df_merged = (pd.merge(left=df_media[merge_cols],\n",
    "                          right=df_conv.reset_index(), \n",
    "                          how='left',\n",
    "                          left_on='d_hash',\n",
    "                          right_on='index').sort_values(by='created_at',  \n",
    "                                                        ascending=True))\n",
    "    df_merged.created_at = pd.to_datetime(df_merged.created_at)\n",
    "    df_merged.to_csv(config.full_metadata_file, \n",
    "                     compression='gzip')\n",
    "else:\n",
    "    df_merged = pd.read_csv(config.full_metadata_file, \n",
    "                            index_col=0, \n",
    "                            compression='gzip')\n",
    "    df_merged.created_at = pd.to_datetime(df_merged.created_at, \n",
    "                                          format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for the mosaic\n",
    "tile_width, tile_height = config.tile_width, config.tile_height # pixel dimenstions per image\n",
    "nx, ny = config.mosiac_width, config.mosiac_height                  # number of images in the x and y axis\n",
    "sample_size = nx * ny\n",
    "aspect_ratio = float(tile_width) / tile_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the dataset\n",
    "df_sample = df_merged.sample(sample_size, random_state=303)\n",
    "min_date = df_sample.created_at.min()\n",
    "max_date = df_sample.created_at.max()\n",
    "images = df_sample.f_img\n",
    "embeddings = encoder.transform(df_sample[config.cols_conv_feats].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic.scatterplot_images(embeddings, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mosaics\n",
    "We can further alter these dimensions by reducing the scatterplot into a grid of images using Mario Klingmann's `rasterfairy` Python package. We'll create two utility functions to crop and center each image (`preprocess_image_for_mosaics`), and one which converts the scatterplot of 2-dimentional image creatures into a nice gridded mosaic (`generate_mosaic`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic.generate_mosaic(embeddings, images, \n",
    "                       mosaic_width=nx, mosaic_height=ny,\n",
    "                       tile_width=tile_width, tile_height=tile_height,\n",
    "                       save_as_file=False, verbose=True, return_image=True,\n",
    "                       title=f\"Mosaic of r/{config.subreddit} \"\n",
    "                             f\"from {min_date.strftime('%Y-%m-%d')} \"\n",
    "                             f\"to {max_date.strftime('%Y-%m-%d')} \"\n",
    "                             f\"author: {config.author}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and Animation\n",
    "We can create animations with mosaics by sorting our initial dataset by time and traversing through the dataset by `offset` images. We'll use the `create_mosaic` function for `n_steps` mosaics. We'll keep the filename for each mosaic and use `ImageIO` to create an mp4 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction on all of them\n",
    "if not os.path.exists(config.two_dim_embeddings_file):\n",
    "    encoder = joblib.load(file_encoder)\n",
    "    embeddings = encoder.transform(df_merged[config.cols_conv_feats].values)\n",
    "    images = df_merged.f_img\n",
    "    two_dim_embeddings = pd.DataFrame({'x' : embeddings[:,0], \n",
    "                                       'y' : embeddings[:,1], \n",
    "                                       'f_img' : images, \n",
    "                                       'created_at' : df_merged.created_at}\n",
    "                                     )\n",
    "    two_dim_embeddings.sort_values(by='created_at', inplace=True, ascending=True)\n",
    "    two_dim_embeddings.to_csv(config.two_dim_embeddings_file, index=False)\n",
    "else:\n",
    "    two_dim_embeddings = pd.read_csv(config.two_dim_embeddings_file)\n",
    "    two_dim_embeddings.created_at = pd.to_datetime(two_dim_embeddings.created_at)\n",
    "    two_dim_embeddings.sort_values(by='created_at', inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = config.offset\n",
    "n_steps = (len(two_dim_embeddings) - sample_size) // offset\n",
    "mosaic_files = []\n",
    "try:\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        # where will the image live?\n",
    "        file_mosaic = os.path.join(config.mosaic_dir, \n",
    "                                   os.path.basename(file_encoder.replace('.pkl', '') \n",
    "                                   + f'__mosaic__offset_{offset}_sample_{sample_size}_step_{i}.png'))\n",
    "        if not os.path.exists(file_mosaic):\n",
    "            # Sample the dataset for images to plot\n",
    "            df_sample = two_dim_embeddings[i * offset : sample_size + (i * offset)]            \n",
    "            min_date = df_sample.created_at.min()\n",
    "            max_date = df_sample.created_at.max()\n",
    "            \n",
    "            emb = df_sample[['x', 'y']].values\n",
    "            img = df_sample.f_img\n",
    "            # create and save the mosaic\n",
    "            mosaic.generate_mosaic(emb, img, \n",
    "                                   mosaic_width=nx, mosaic_height=ny,\n",
    "                                   tile_width=tile_width, tile_height=tile_height,\n",
    "                                   save_as_file=file_mosaic, return_image=False,\n",
    "                                   title=f\"Mosaic of r/{config.subreddit} \"\n",
    "                                         f\"from {min_date.strftime('%Y-%m-%d')} \"\n",
    "                                         f\"to {max_date.strftime('%Y-%m-%d')} \"\n",
    "                                         f\"author {config.author} - Frame {i}\")\n",
    "        mosaic_files.append(file_mosaic)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Cancelled early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mosaic_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mp4(files, dest, fps=30):\n",
    "    '''\n",
    "    Takes a list of image filepaths..\n",
    "    Uses ImageIO to combine images into an mp4.\n",
    "    '''\n",
    "    images = []\n",
    "    writer = imageio.get_writer(dest, fps=fps)\n",
    "    for f_img in files:\n",
    "        img = Image.open(f_img)\n",
    "        writer.append_data(np.array(img))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageio.plugins.ffmpeg.download()\n",
    "filename = datetime.now().isoformat() + '-' + config.subreddit + '.mp4'\n",
    "filepath = os.path.join(config.output_dir, filename)\n",
    "make_mp4(mosaic_files, filepath, fps=config.fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knobs to turn:<br>\n",
    "- Experiment with UMAP parameters.<br>\n",
    "- Change the pretrained neural network for the feature extraction step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
