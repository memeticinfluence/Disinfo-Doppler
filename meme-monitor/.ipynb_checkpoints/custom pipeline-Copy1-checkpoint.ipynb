{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "structured-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import context_manager\n",
    "import data_sources.pushshift as ps\n",
    "from image_utils import download_media_and_return_dhash, read_image\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "import umap\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from config import cols_conv_feats, skip_hash\n",
    "from image_utils import read_image, read_and_transform_image\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dying-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from rasterfairy import transformPointCloud2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acknowledged-clothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are we using a GPU? If not, the device will be using cpu\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "declared-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cols_conv_feats, skip_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "union-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "impossible-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddit_context(subreddit):\n",
    "    '''\n",
    "    Where will data be saved?\n",
    "    '''\n",
    "    sub_dir = os.path.join(config.data_dir, subreddit)\n",
    "    sub_config_dir = os.path.join(config.data_dir, subreddit, \"config\")\n",
    "    media_dir =  os.path.join(config.data_dir, 'media')\n",
    "    file_subreddit = os.path.join(sub_dir, 'posts.csv.gz')\n",
    "    file_subreddit_media = os.path.join(sub_dir, 'media.csv.gz')\n",
    "    image_metas = os.path.join(config.data_dir, subreddit, \"image_metas\")\n",
    "    logits_dir = os.path.join(config.data_dir, subreddit, \"image_features\")\n",
    "    full_metadata_dir = os.path.join(config.data_dir, subreddit, \"full_metadata\")\n",
    "    \n",
    "    for _dir in [config.data_dir, sub_dir, media_dir, sub_config_dir, image_metas, logits_dir, full_metadata_dir]:\n",
    "        os.makedirs(_dir, exist_ok=True)\n",
    "        \n",
    "    context = {\n",
    "        'data_dir' : config.data_dir,\n",
    "        'sub_dir' : sub_dir,\n",
    "        \"sub_config_dir\":sub_config_dir,\n",
    "        'media_dir' : media_dir,\n",
    "        'file_subreddit' : file_subreddit,\n",
    "        'file_subreddit_media' : file_subreddit_media,\n",
    "        \"image_metas\": image_metas,\n",
    "        \"logits_dir\": logits_dir,\n",
    "        \"full_metadata_dir\": full_metadata_dir\n",
    "    }\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chronic-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "subreddit = \"dankmemes\"\n",
    "\n",
    "input_date = '20210102'\n",
    "\n",
    "date = pd.to_datetime(input_date).date()\n",
    "\n",
    "next_date = date + pd.to_timedelta(\"1D\")\n",
    "\n",
    "\n",
    "start_ux = int(time.mktime(date.timetuple()))\n",
    "end_ux = int(time.mktime(next_date.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceramic-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = get_subreddit_context(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seeing-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_dir': 'data/platforms/reddit',\n",
       " 'sub_dir': 'data/platforms/reddit\\\\dankmemes',\n",
       " 'sub_config_dir': 'data/platforms/reddit\\\\dankmemes\\\\config',\n",
       " 'media_dir': 'data/platforms/reddit\\\\media',\n",
       " 'file_subreddit': 'data/platforms/reddit\\\\dankmemes\\\\posts.csv.gz',\n",
       " 'file_subreddit_media': 'data/platforms/reddit\\\\dankmemes\\\\media.csv.gz',\n",
       " 'image_metas': 'data/platforms/reddit\\\\dankmemes\\\\image_metas',\n",
       " 'logits_dir': 'data/platforms/reddit\\\\dankmemes\\\\image_features',\n",
       " 'full_metadata_dir': 'data/platforms/reddit\\\\dankmemes\\\\full_metadata'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mediterranean-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = context['sub_config_dir']+\"/\"+input_date+\".csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "knowing-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(new_dir):\n",
    "    df = pd.read_csv(new_dir)\n",
    "else:\n",
    "    records = ps.download_subreddit_posts(subreddit, start_ux, end_ux, verbose=False)\n",
    "    df = pd.DataFrame(records)\n",
    "    df['preview'] = df['preview'].apply(json.dumps)\n",
    "    df.to_csv(new_dir, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "growing-dating",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['preview'] = df['preview'].fillna(\"{}\").apply(json.loads)\n",
    "\n",
    "df_media = df[~df.preview.isnull()]\n",
    "\n",
    "df_media = df_media.to_dict(orient='rocords')\n",
    "\n",
    "image_meta_dir = context['image_metas']+\"/\"+input_date+\".csv.gz\"\n",
    "\n",
    "if os.path.exists(image_meta_dir):\n",
    "    _df_img_meta = pd.read_csv(image_meta_dir)\n",
    "else:\n",
    "    img_meta = []\n",
    "    bar = tqdm(total=len(df_media))\n",
    "\n",
    "    for row in df_media:\n",
    "        preview = row.get('preview')\n",
    "        if preview:\n",
    "            images = preview.get('images')\n",
    "            if not images:\n",
    "                continue\n",
    "            for img in images:\n",
    "                r = row.copy()\n",
    "                img_url, f_img = context_manager.get_media_context(img, context)\n",
    "                if not img_url:\n",
    "                    continue\n",
    "                try:\n",
    "                    d_hash, img_size = download_media_and_return_dhash(img_url, f_img)\n",
    "                except:\n",
    "                    print(\"ERROR!\")\n",
    "                    continue\n",
    "\n",
    "                if img_size != 0:\n",
    "                    r['deleted'] = False\n",
    "                    r['d_hash'] = d_hash\n",
    "                    r['f_img'] = f_img \n",
    "                    r['img_size'] = img_size\n",
    "                else:\n",
    "                    r['deleted'] = True\n",
    "                    r['d_hash'] = d_hash\n",
    "                    r['f_img'] = f_img \n",
    "                    r['img_size'] = img_size\n",
    "                img_meta.append(r)\n",
    "        bar.update(1)\n",
    "    _df_img_meta = pd.DataFrame(img_meta)\n",
    "    _df_img_meta.to_csv(image_meta_dir, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "forty-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>media</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>deleted</th>\n",
       "      <th>d_hash</th>\n",
       "      <th>f_img</th>\n",
       "      <th>img_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>harrycrunk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_1qfqw61e</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>131729094545070f</td>\n",
       "      <td>data/platforms/reddit\\media\\q_\\er\\Q_erM3a_lYvf...</td>\n",
       "      <td>26550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Thelazytimetraveller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': 'mod collector '}, {'a': '...</td>\n",
       "      <td>mod collector :beeg_yoshi::sooz_bow::noodles::...</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_4woom0lt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>491b2e1721393167</td>\n",
       "      <td>data/platforms/reddit\\media\\rw\\1c\\rw1CuUoizYJG...</td>\n",
       "      <td>56118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>PowerfulOperation8</td>\n",
       "      <td>pulse</td>\n",
       "      <td>[{'a': ':maymay:', 'e': 'emoji', 'u': 'https:/...</td>\n",
       "      <td>:maymay: Maymaymaker :maymay:</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_38jvij40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NOHASH</td>\n",
       "      <td>data/platforms/reddit\\media\\2x\\ew\\2XewVSYnZPxv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>calizoomer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': '☣️'}]</td>\n",
       "      <td>☣️</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_69d7qby2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>53910663d1d0ccde</td>\n",
       "      <td>data/platforms/reddit\\media\\ro\\h-\\rOh-pn26Lwif...</td>\n",
       "      <td>104050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>theredditor13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_4m6vn0cv</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>7c1a094b70e02879</td>\n",
       "      <td>data/platforms/reddit\\media\\-f\\ta\\-FtAzj7sYjDd...</td>\n",
       "      <td>108619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Inkling4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': '☝ FOREVER NUMBER ONE ☝'}]</td>\n",
       "      <td>☝ FOREVER NUMBER ONE ☝</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_yq2n8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2bc0d194e6eea4c8</td>\n",
       "      <td>data/platforms/reddit\\media\\vm\\pd\\vmPDZQhLyqas...</td>\n",
       "      <td>46502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>HRUDUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_8zqqcbc8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>moderator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>c099a6723371d872</td>\n",
       "      <td>data/platforms/reddit\\media\\ul\\gz\\ULgZ97Q-VzAK...</td>\n",
       "      <td>48617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Sike1dj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_a8zez</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>6333212701a62404</td>\n",
       "      <td>data/platforms/reddit\\media\\6u\\ud\\6uUdCuHm2y30...</td>\n",
       "      <td>143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>XxF1RExX</td>\n",
       "      <td>pulse</td>\n",
       "      <td>[{'e': 'text', 't': 'bitly.com/1H9DQSz'}]</td>\n",
       "      <td>bitly.com/1H9DQSz</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_38hew926</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>a09c9d9c9e9e46a7</td>\n",
       "      <td>data/platforms/reddit\\media\\kz\\0z\\kz0zjYeCnTSa...</td>\n",
       "      <td>175871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>ZachVII7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_4zdtpa2o</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>43cbe399f2737363</td>\n",
       "      <td>data/platforms/reddit\\media\\qi\\aa\\qiAAe7jry1La...</td>\n",
       "      <td>439044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2315 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     all_awardings  allow_live_comments                author  \\\n",
       "0               []                False            harrycrunk   \n",
       "1               []                False  Thelazytimetraveller   \n",
       "2               []                False    PowerfulOperation8   \n",
       "3               []                False            calizoomer   \n",
       "4               []                False         theredditor13   \n",
       "...            ...                  ...                   ...   \n",
       "2310            []                False              Inkling4   \n",
       "2311            []                False                HRUDUS   \n",
       "2312            []                False               Sike1dj   \n",
       "2313            []                False              XxF1RExX   \n",
       "2314            []                False              ZachVII7   \n",
       "\n",
       "     author_flair_css_class  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                     pulse   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "...                     ...   \n",
       "2310                    NaN   \n",
       "2311                    NaN   \n",
       "2312                    NaN   \n",
       "2313                  pulse   \n",
       "2314                    NaN   \n",
       "\n",
       "                                  author_flair_richtext  \\\n",
       "0                                                    []   \n",
       "1     [{'e': 'text', 't': 'mod collector '}, {'a': '...   \n",
       "2     [{'a': ':maymay:', 'e': 'emoji', 'u': 'https:/...   \n",
       "3                            [{'e': 'text', 't': '☣️'}]   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "2310     [{'e': 'text', 't': '☝ FOREVER NUMBER ONE ☝'}]   \n",
       "2311                                                 []   \n",
       "2312                                                 []   \n",
       "2313          [{'e': 'text', 't': 'bitly.com/1H9DQSz'}]   \n",
       "2314                                                 []   \n",
       "\n",
       "                                      author_flair_text author_flair_type  \\\n",
       "0                                                   NaN              text   \n",
       "1     mod collector :beeg_yoshi::sooz_bow::noodles::...          richtext   \n",
       "2                         :maymay: Maymaymaker :maymay:          richtext   \n",
       "3                                                    ☣️          richtext   \n",
       "4                                                   NaN              text   \n",
       "...                                                 ...               ...   \n",
       "2310                             ☝ FOREVER NUMBER ONE ☝          richtext   \n",
       "2311                                                NaN              text   \n",
       "2312                                                NaN              text   \n",
       "2313                                  bitly.com/1H9DQSz          richtext   \n",
       "2314                                                NaN              text   \n",
       "\n",
       "     author_fullname  author_patreon_flair  author_premium  ...  \\\n",
       "0        t2_1qfqw61e                 False           False  ...   \n",
       "1        t2_4woom0lt                 False           False  ...   \n",
       "2        t2_38jvij40                 False           False  ...   \n",
       "3        t2_69d7qby2                 False           False  ...   \n",
       "4        t2_4m6vn0cv                 False           False  ...   \n",
       "...              ...                   ...             ...  ...   \n",
       "2310        t2_yq2n8                 False           False  ...   \n",
       "2311     t2_8zqqcbc8                 False           False  ...   \n",
       "2312        t2_a8zez                 False           False  ...   \n",
       "2313     t2_38hew926                 False            True  ...   \n",
       "2314     t2_4zdtpa2o                 False           False  ...   \n",
       "\n",
       "     removed_by_category  author_cakeday  media  media_embed secure_media  \\\n",
       "0                    NaN             NaN    NaN          NaN          NaN   \n",
       "1                    NaN             NaN    NaN          NaN          NaN   \n",
       "2                    NaN             NaN    NaN          NaN          NaN   \n",
       "3                    NaN             NaN    NaN          NaN          NaN   \n",
       "4                    NaN             NaN    NaN          NaN          NaN   \n",
       "...                  ...             ...    ...          ...          ...   \n",
       "2310                 NaN             NaN    NaN          NaN          NaN   \n",
       "2311           moderator             NaN    NaN          NaN          NaN   \n",
       "2312                 NaN             NaN    NaN          NaN          NaN   \n",
       "2313                 NaN             NaN    NaN          NaN          NaN   \n",
       "2314                 NaN             NaN    NaN          NaN          NaN   \n",
       "\n",
       "     secure_media_embed deleted            d_hash  \\\n",
       "0                   NaN   False  131729094545070f   \n",
       "1                   NaN   False  491b2e1721393167   \n",
       "2                   NaN    True            NOHASH   \n",
       "3                   NaN   False  53910663d1d0ccde   \n",
       "4                   NaN   False  7c1a094b70e02879   \n",
       "...                 ...     ...               ...   \n",
       "2310                NaN   False  2bc0d194e6eea4c8   \n",
       "2311                NaN   False  c099a6723371d872   \n",
       "2312                NaN   False  6333212701a62404   \n",
       "2313                NaN   False  a09c9d9c9e9e46a7   \n",
       "2314                NaN   False  43cbe399f2737363   \n",
       "\n",
       "                                                  f_img  img_size  \n",
       "0     data/platforms/reddit\\media\\q_\\er\\Q_erM3a_lYvf...     26550  \n",
       "1     data/platforms/reddit\\media\\rw\\1c\\rw1CuUoizYJG...     56118  \n",
       "2     data/platforms/reddit\\media\\2x\\ew\\2XewVSYnZPxv...         0  \n",
       "3     data/platforms/reddit\\media\\ro\\h-\\rOh-pn26Lwif...    104050  \n",
       "4     data/platforms/reddit\\media\\-f\\ta\\-FtAzj7sYjDd...    108619  \n",
       "...                                                 ...       ...  \n",
       "2310  data/platforms/reddit\\media\\vm\\pd\\vmPDZQhLyqas...     46502  \n",
       "2311  data/platforms/reddit\\media\\ul\\gz\\ULgZ97Q-VzAK...     48617  \n",
       "2312  data/platforms/reddit\\media\\6u\\ud\\6uUdCuHm2y30...    143750  \n",
       "2313  data/platforms/reddit\\media\\kz\\0z\\kz0zjYeCnTSa...    175871  \n",
       "2314  data/platforms/reddit\\media\\qi\\aa\\qiAAe7jry1La...    439044  \n",
       "\n",
       "[2315 rows x 78 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_img_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gross-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 185/185 [00:13<00:00, 14.05it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-80080834f341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[0maspect_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_width\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtile_height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m \u001b[0mdf_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[0mwanted_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"full_link\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sample' is not defined"
     ]
    }
   ],
   "source": [
    "_df_img_meta = _df_img_meta[~_df_img_meta['d_hash'].isin(skip_hash)] \n",
    "\n",
    "# The image needs to be specific dimensions, normalized, and converted to a Tensor to be read into a PyTorch model.\n",
    "scaler = transforms.Resize((224, 224))\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# this is the order of operations that will occur on each image.\n",
    "transformations = transforms.Compose([scaler, \n",
    "                                      to_tensor, \n",
    "                                      normalizer])\n",
    "\n",
    "class Feature_Extraction_Dataset(Dataset):\n",
    "    \"\"\"Dataset wrapping images and file names\n",
    "    img_col is the column for the image to be read\n",
    "    index_col is a unique value to index the extracted features\n",
    "    \"\"\"\n",
    "    def __init__(self, df, img_col, index_col):\n",
    "        # filter out rows where the file is not on disk.\n",
    "        self.X_train = df.drop_duplicates(subset='d_hash').reset_index(drop=True)\n",
    "        self.files = self.X_train[img_col]\n",
    "        self.idx = self.X_train[index_col]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_idx = self.idx[index]\n",
    "        img_file = self.files[index]\n",
    "        try:\n",
    "            img = read_and_transform_image(self.files[index], transformations)\n",
    "            return img, img_file, img_idx\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train.index)\n",
    "\n",
    "dataset = Feature_Extraction_Dataset(_df_img_meta, \n",
    "                                     img_col='f_img', \n",
    "                                     index_col='d_hash')\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=config.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)\n",
    "\n",
    "def load_resnet_for_feature_extraction():\n",
    "    # Load a pre-trained model\n",
    "    res50_model = models.resnet50(pretrained=True)\n",
    "    # Pop the last Dense layer off. This will give us convolutional features.\n",
    "    res50_conv = nn.Sequential(*list(res50_model.children())[:-1])\n",
    "    res50_conv.to(device)\n",
    "\n",
    "    # Don't run backprop!\n",
    "    for param in res50_conv.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # we won't be training the model. Instead, we just want predictions so we switch to \"eval\" mode. \n",
    "    res50_conv.eval();\n",
    "    \n",
    "    return res50_conv\n",
    "\n",
    "res50_conv = load_resnet_for_feature_extraction()\n",
    "\n",
    "logits_dir = context['logits_dir']+\"/\"+input_date+\".csv.gz\"\n",
    "\n",
    "conv = None\n",
    "\n",
    "if os.path.exists(logits_dir):\n",
    "    conv = pd.read_csv(logits_dir, index_col=0).drop_duplicates()\n",
    "\n",
    "df_convs = []\n",
    "for (X, img_file, idx) in tqdm(data_loader):\n",
    "    filt = [i for i in idx if i not in conv.index] if conv is not None else [i for i in idx]\n",
    "    if filt:\n",
    "        X = X.to(device)\n",
    "        logits = res50_conv(X)\n",
    "        #logits.size() # [`batch_size`, 2048, 1, 1])\n",
    "\n",
    "        logits = logits.squeeze(2) # remove the extra dims\n",
    "        logits = logits.squeeze(2) # remove the extra dims\n",
    "        #logits.size() # [`batch_size`, 2048]\n",
    "\n",
    "        n_dimensions = logits.size(1)\n",
    "        logits_dict = dict(zip(idx, logits.cpu().data.numpy()))\n",
    "        #{'filename' : np.array([x0, x1, ... x2047])}\n",
    "\n",
    "        df_conv = pd.DataFrame.from_dict(logits_dict, \n",
    "                                         columns=cols_conv_feats, \n",
    "                                         orient='index')\n",
    "        # add a column for the filename of images...\n",
    "        df_conv['f_img'] = img_file\n",
    "        df_conv = df_conv.loc[filt]\n",
    "        df_convs.append(df_conv)    \n",
    "\n",
    "conv = pd.concat([conv, *df_convs]).drop_duplicates()\n",
    "\n",
    "conv.to_csv(logits_dir, compression='gzip')\n",
    "\n",
    "# UMAP Params\n",
    "n_neighbors = 25\n",
    "metric = 'euclidean'\n",
    "min_dist = 0.5\n",
    "training_set_size = config.umap_training_set_size\n",
    "overwrite_model = False # set to True to re-train the model.\n",
    "os.makedirs(f'{ config.working_dir }/encoders',exist_ok=True)\n",
    "os.makedirs(f'{ config.working_dir }/umap_training_data',exist_ok=True)\n",
    "# Model files\n",
    "file_encoder = (f'{ config.working_dir }/encoders/{ str(min_dist).replace(\".\", \"-\") }_'\n",
    "                f'dist_{ metric }_sample_{ training_set_size }_{input_date}.pkl')\n",
    "file_training_set = f'{ config.working_dir }/{ training_set_size }_{input_date}.csv'\n",
    "\n",
    "if not os.path.exists(file_encoder) or overwrite_model:\n",
    "    # Create the training set (note: UMAP can be either supervised or unsupervised.)\n",
    "    if not os.path.exists(file_training_set):\n",
    "        training_set = conv[config.cols_conv_feats].sample(training_set_size, \n",
    "                                                              random_state=303)\n",
    "    else:\n",
    "        training_set = pd.read_csv(file_training_set, \n",
    "                                   index_col=0)\n",
    "    \n",
    "    # fit the model scikit-learn style\n",
    "    encoder = umap.UMAP(n_neighbors=n_neighbors,\n",
    "                        min_dist=min_dist,\n",
    "                        metric=metric,\n",
    "                        random_state=303,\n",
    "                        verbose=1).fit(training_set.values)\n",
    "\n",
    "    # save the model for later! Save the training data, too.\n",
    "    joblib.dump(encoder, file_encoder)                             \n",
    "    training_set.to_csv(file_training_set)\n",
    "else:\n",
    "    encoder = joblib.load(file_encoder)\n",
    "    encoder\n",
    "\n",
    "logits_dir = context['full_metadata_dir']+\"/\"+input_date+\".csv.gz\"\n",
    "\n",
    "_df_img_meta\n",
    "\n",
    "# Join the image metadata with convolutional features\n",
    "if not os.path.exists(logits_dir):\n",
    "    # Merge the datasets\n",
    "    merge_cols = [c for c in _df_img_meta.columns if c != 'f_img']\n",
    "    df_merged = pd.merge(left=_df_img_meta[merge_cols],\n",
    "                          right=conv.reset_index(), \n",
    "                          how='left',\n",
    "                          left_on='d_hash',\n",
    "                          right_on='index')\n",
    "    df_merged.to_csv(logits_dir, \n",
    "                     compression='gzip')\n",
    "else:\n",
    "    df_merged = pd.read_csv(logits_dir, \n",
    "                            index_col=0, \n",
    "                            compression='gzip')\n",
    "\n",
    "tile_width, tile_height = config.tile_width, config.tile_height # pixel dimenstions per image\n",
    "\n",
    "nx = config.mosiac_width # number of images in the x and y axis\n",
    "ny = df_merged.shape[0] // nx\n",
    "sample_size = nx * ny\n",
    "aspect_ratio = float(tile_width) / tile_height\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "declared-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample = df_merged.sample(sample_size, random_state=303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sonic-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "textile-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "killing-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [00:15, 95.33it/s] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ImageDraw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-6d195df4f6a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# write an annotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', int(tile_height * 1.2) )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmosaic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m draw.text((4, (tile_height * (mosaic_height)) + 10), \n\u001b[0;32m     26\u001b[0m            title, title_rbg)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDraw' is not defined"
     ]
    }
   ],
   "source": [
    "full_width = tile_width * nx\n",
    "full_height = tile_height * (ny + 2)\n",
    "aspect_ratio = float(tile_width) / tile_height\n",
    "\n",
    "# create an empty image for the mosaic\n",
    "mosaic = Image.new('RGB', (full_width, full_height))\n",
    "\n",
    "# iterate through each image and where it is possed to live.\n",
    "for f_img, (idx_x, idx_y) in tqdm(zip(images, grid_assignment[0]), \n",
    "                                  disable = False):\n",
    "    # Find exactly where the image will be\n",
    "    x, y = tile_width * idx_x, tile_height * idx_y\n",
    "\n",
    "    # read the image, center crop the image and add it to the mosaic\n",
    "    try:\n",
    "        img = Image.open(f_img).convert('RGBA')\n",
    "        tile = resize_image(img, tile_width, tile_height, aspect_ratio)\n",
    "        mosaic.paste(tile, (int(x), int(y)))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to add image {f_img} see error:\\n{e}\")    \n",
    "\n",
    "# write an annotation\n",
    "#fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', int(tile_height * 1.2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_height = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "forty-treat",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown color specifier: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-684d564b52fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmosaic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m draw.text((4, (tile_height * (ny)) + 10), \n\u001b[1;32m----> 3\u001b[1;33m            \"title\", \"\")\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mohammed\\miniconda3\\envs\\py37\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self, xy, text, fill, font, anchor, spacing, align, direction, features, language, stroke_width, stroke_fill, embedded_color, *args, **kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_bitmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0mink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mink\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[0mstroke_ink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mohammed\\miniconda3\\envs\\py37\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mgetink\u001b[1;34m(fill)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mgetink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mink\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mohammed\\miniconda3\\envs\\py37\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36m_getink\u001b[1;34m(self, ink, fill)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mink\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                     \u001b[0mink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                     \u001b[0mink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mohammed\\miniconda3\\envs\\py37\\lib\\site-packages\\PIL\\ImageColor.py\u001b[0m in \u001b[0;36mgetcolor\u001b[1;34m(color, mode)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m    130\u001b[0m     \u001b[1;31m# same as getrgb, but converts the result to the given mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetrgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mohammed\\miniconda3\\envs\\py37\\lib\\site-packages\\PIL\\ImageColor.py\u001b[0m in \u001b[0;36mgetrgb\u001b[1;34m(color)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"unknown color specifier: {repr(color)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unknown color specifier: ''"
     ]
    }
   ],
   "source": [
    "draw = ImageDraw.Draw(mosaic)\n",
    "draw.text((4, (tile_height * (ny)) + 10), \n",
    "           \"title\", title_rbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "equal-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  100 epochs\n",
      "\tcompleted  10  /  100 epochs\n",
      "\tcompleted  20  /  100 epochs\n",
      "\tcompleted  30  /  100 epochs\n",
      "\tcompleted  40  /  100 epochs\n",
      "\tcompleted  50  /  100 epochs\n",
      "\tcompleted  60  /  100 epochs\n",
      "\tcompleted  70  /  100 epochs\n",
      "\tcompleted  80  /  100 epochs\n",
      "\tcompleted  90  /  100 epochs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8c4cd0480921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_assignment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0moutput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subreddit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0moutput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_sample = df_merged.sample(sample_size, random_state=303)\n",
    "images = df_sample.f_img\n",
    "embeddings = encoder.transform(df_sample[config.cols_conv_feats].values)\n",
    "\n",
    "import mosaic\n",
    "\n",
    "grid_assignment = transformPointCloud2D(embeddings, \n",
    "                                            target=(nx, \n",
    "                                                    ny))\n",
    "\n",
    "grid_assignment\n",
    "\n",
    "df_sample[['x', 'y']] = grid_assignment[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adequate-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1466    data/platforms/reddit\\media\\ty\\3f\\ty3fOqjq7uP3...\n",
       "1341    data/platforms/reddit\\media\\wb\\sg\\WBsGJM2EeEHh...\n",
       "1178    data/platforms/reddit\\media\\dk\\jy\\dKJYtpeu8jHR...\n",
       "1334    data/platforms/reddit\\media\\8t\\j2\\8tj2bkzxb08x...\n",
       "78      data/platforms/reddit\\media\\n6\\rc\\N6RcVjoW9DUl...\n",
       "                              ...                        \n",
       "975     data/platforms/reddit\\media\\ft\\qg\\ftqgGJZYCCmG...\n",
       "180     data/platforms/reddit\\media\\49\\nf\\49nF0M1E-1m3...\n",
       "369     data/platforms/reddit\\media\\0u\\o_\\0uO_iHiMeAcF...\n",
       "370     data/platforms/reddit\\media\\be\\yu\\Beyuxf2o4S37...\n",
       "200     data/platforms/reddit\\media\\ye\\n4\\YEn4gpv7CBGs...\n",
       "Name: f_img, Length: 1500, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-neutral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_connection():\n",
    "    db = create_engine(\n",
    "        \"mysql://admin:coffee-admin@coffee.cp82lr4f5r06.us-east-2.rds.amazonaws.com:3306/db?charset=utf8\",\n",
    "        encoding=\"utf8\",\n",
    "    )\n",
    "    return db\n",
    "\n",
    "db = get_sql_connection()\n",
    "\n",
    "wanted_cols = [\"url\", \"full_link\", \"x\", \"y\"]\n",
    "\n",
    "output_df = df_sample[wanted_cols]\n",
    "\n",
    "output_df.to_sql(\"mosaics\", db, index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-place",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-logging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-richardson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-outline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-teach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-shanghai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-seeker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-construction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-savage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-motel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-plastic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-dictionary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-republic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
